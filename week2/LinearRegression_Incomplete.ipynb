{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression-Incomplete.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPnwA9zSsXg6",
        "colab_type": "text"
      },
      "source": [
        "# ACM Research Week 2: Linear Regression\n",
        "\n",
        "## Background\n",
        "### Dot Product\n",
        "Assume we have two vectors $\\vec{v} = (v_1, v_2, ..., v_n)$ and $\\vec{w} = (w_1, w_2, ..., w_n)$.\n",
        "\n",
        "The *dot product* is defined as the sum of the product of corresponding components:\n",
        "\n",
        "$$\\vec{v}\\cdot\\vec{w} = v_1 w_1 + v_2 w_2 + ... + v_n w_n$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2GjF330sT0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6043979-f635-4e1e-9306-b11dd4ecac37"
      },
      "source": [
        "import numpy as np\n",
        "v = np.array([1, 2])\n",
        "w = np.array([3, 4])\n",
        "# Dot product here!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8tadAO2TDOt",
        "colab_type": "text"
      },
      "source": [
        "### Matrix Multiplication\n",
        "Let's say have two matrices $A$ and $B$ as defined below:\n",
        "\n",
        "$$\n",
        "A = \\begin{bmatrix} 1 & 2 & 3 \\\\ 4 & 5 & 6 \\end{bmatrix},\\:\\:\n",
        "B = \\begin{bmatrix} 7 & 8 \\\\ 9 & 10 \\\\ 11 & 12 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "The *product* $AB$ of two matrices is defined as the dot product between the rows of $A$ with the columns of $B$:\n",
        "\n",
        "$$AB = \\begin{bmatrix}\n",
        "1(7) + 2(9) + 3(11) & 1(8) + 2(10) + 3(12) \\\\\n",
        "4(7) + 5(9) + 6(11) & 4(8) + 5(10) + 6(12)\n",
        "\\end{bmatrix} = \\begin{bmatrix}58 & 64 \\\\ 139 & 154\\end{bmatrix}$$\n",
        "\n",
        "Note than if $A$ is of $a \\times b$ and $B$ is of $b \\times c$, then $AB$ is of size $a \\times c$. \n",
        "\n",
        "The product also doesn't exist if the number of rows in A doesn't match the number of columns in C."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jWU5NgpTQ8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11c3c747-f516-4a14-bf37-c9ed4ea3e99f"
      },
      "source": [
        "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "B = np.array([[7, 8], [9, 10], [11, 12]])\n",
        "# Multiply matrices here!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 58,  64],\n",
              "       [139, 154]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB89COaDTRUx",
        "colab_type": "text"
      },
      "source": [
        "### Transpose a Matrix\n",
        "Rows <-> columns. That's it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKWdoDQOTSRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "890208fa-2a30-47fd-b552-0871d05b6a36"
      },
      "source": [
        "# Transpose here!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 4],\n",
              "       [2, 5],\n",
              "       [3, 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bok2KFgKTTEY",
        "colab_type": "text"
      },
      "source": [
        "## Main Content\n",
        "\n",
        "### Intro\n",
        "\n",
        "**Linear regression** is one of the most basic machine learning tasks: fit a linear model to some data.\n",
        "\n",
        "You might have seen a line in 2D as $y=mx+b$, where $m$ is the slope and $b$ is the y-intercept.\n",
        "\n",
        "Let's first *vectorize*, this, i.e. think of it within the realm of matrix multiplication. Instead of writing our line as $y=mx+b$, we can rewrite the right side of that equation as $y = w^{\\top}x$, where $x_0 = 1$ and $w$ is a $1\\times 2$ vector.\n",
        "\n",
        "As an example, how would we write the equation $y=3x+4$ in this form?\n",
        "Well, $w = \\begin{bmatrix} 4 \\\\ 3 \\end{bmatrix}$, and $x = \\begin{bmatrix} 1 \\\\ x_1 \\end{bmatrix}$, where $x_1$ takes the place of $x$ in the slope-intercept form equation. We can verify this is the same by multiplying it out:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "y &= w^{\\top} x \\\\\n",
        "y &= \\begin{bmatrix} 4 & 3 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ x_1 \\end{bmatrix} \\\\\n",
        "y &= 4 + 3x_1 \\;\\checkmark\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV9Q_YJGTXtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b6f0f54e-8687-41be-cb95-c23147cde0f7"
      },
      "source": [
        "def equation(x1):\n",
        "  # Equation here!\n",
        "print(equation(1))\n",
        "print(equation(4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[7]]\n",
            "[[16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGd2uovYTZBn",
        "colab_type": "text"
      },
      "source": [
        "### Multivariate Linear Equations: Vectorized\n",
        "Now, let's extend this concept to multiple dimensions and multiple points.\n",
        "Let's say we had the equation $y = w_0x_0 +w_1 x_1 + w_2 x_2 + ... + w_n x_n$. This is a line in $n$ dimensionsâ€”for us, we'll say this model takes $n$ *features*. How would we vectorize this, and use it for multiple points?\n",
        "\n",
        "Let's say we have the **design matrix**:\n",
        "$$\n",
        "X = \\begin{bmatrix}\n",
        "1 & 0.315 & 0.083 & 0.849 \\\\\n",
        "1 & 0.522 & 0.079 & 0.530 \\\\\n",
        "1 & 0.558 & 0.252 & 0.958 \\\\\n",
        "1 & 0.134 & 0.241 & 0.473\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Here, we have 3 *features* and 4 *data points*/*training examples*. We can also say $n=3$ and $m=4$.\n",
        "\n",
        "Let's say we also have a vector of *weights*:\n",
        "\n",
        "$$ w = \n",
        "\\begin{bmatrix}\n",
        "w_0 \\\\\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "0.012 \\\\\n",
        "0.951 \\\\\n",
        "0.301 \\\\\n",
        "0.868\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "Therefore, the vectorized version of the multivariate linear equation above would be:\n",
        "\n",
        "$$ y = Xw $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLwxCmg5TeeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array([\n",
        "     [1, 0.315, 0.083, 0.849],\n",
        "     [1, 0.522, 0.079, 0.530],\n",
        "     [1, 0.558, 0.252, 0.958],\n",
        "     [1, 0.134, 0.241, 0.473]\n",
        "])\n",
        "w = np.array([[0.012], [0.951], [0.301], [0.868]])\n",
        "# y = X times w!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgmxNpWwTe97",
        "colab_type": "text"
      },
      "source": [
        "### The Problem of Linear Regression\n",
        "With this knowledge, we can now talk about multivariate linear regression.\n",
        "\n",
        "> **The task $T$**: With equation $\\hat{y} = Xw$, have $\\hat{y} \\approx y$ for any $X$ by finding the optimal $w$.\n",
        "\n",
        "> **The experience $E$**: $X_{train}$, as provided\n",
        "\n",
        "> **Performance measure $P$**: (Euclidean) distance from $\\hat{y}$ to $y$\n",
        "\n",
        "Let's define all of these in terms of matrices and matrix equations:\n",
        "\n",
        "- The task $T$: $\\hat{y} = Xw$, $w \\in \\mathbb{R}^n$\n",
        "- The experience $E$: design matrix of data points\n",
        "- The performance measure $P$: $J(w) = ||\\hat{y}- y||^2$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "375TBdpuUk74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3afd8515-94e4-4d46-8d7d-42cbe69318bd"
      },
      "source": [
        "y_hat = np.array([[1.1283],\n",
        "       [1.0000],\n",
        "       [1.43],\n",
        "       [0.6234]])\n",
        "# print performance measure!\n",
        "y_hat = np.array([[1.07348 ],\n",
        "       [0.992241],\n",
        "       [1.450054],\n",
        "       [0.622539]])\n",
        "# print performance measure!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.003032619598487279\n",
            "5.082120056479053e-32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP3p_V8rUla-",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent\n",
        "How do we use $P$ to get better at $T$?\n",
        "\n",
        "The answer is **gradient descent**. The basic idea behind gradient descent is to use the *partial derivative* of a function to iteratively converge to a (ideally global) minimum.\n",
        "\n",
        "The since this is vectorized, we need to find the partial derivative with respect to every parameter in $w$. In linear algebra, this is also called the gradient $\\nabla$. The gradient of the MSE function is $$\\nabla J(w) = \\frac{1}{m} X^{\\top}(Xw - y)$$\n",
        "\n",
        "So how do we update the weights $w$ given the gradient? Well, we multiply the gradient by a small decimal $\\alpha$ (called the *learning rate*), which is usually set to something small like `0.001` and subtract it from the existing weights.\n",
        "\n",
        "> **Note**: The learning rate will be different for every dataset and ML algorithm. Set it too small, and your model will take forever to *converge* (reach the minimum). Set it too high, and it may overshoot the minimum and fail to converge.\n",
        "\n",
        "As a matrix equation, it looks something like this:\n",
        "\n",
        "$$w = w - \\frac{\\alpha}{m}X^{\\top}(Xw - y)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scInKKN2U_cN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "1667f28a-0735-470d-a04f-3834482b7e07"
      },
      "source": [
        "X = np.array([\n",
        "     [1, 0.315, 0.083, 0.849],\n",
        "     [1, 0.522, 0.079, 0.530],\n",
        "     [1, 0.558, 0.252, 0.958],\n",
        "     [1, 0.134, 0.241, 0.473]\n",
        "])\n",
        "w = np.array([[0.012], [0.951], [0.301], [0.868]])\n",
        "y_hat = np.dot(X, w)\n",
        "y = np.array([[1.5],\n",
        "       [0.23],\n",
        "       [1.0],\n",
        "       [0.6]])\n",
        "alpha = 0.001\n",
        "m = 4\n",
        "# iteratively do gradient descent!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01179792]\n",
            " [0.95087058]\n",
            " [0.30096408]\n",
            " [0.86787908]]\n",
            "[[0.01159619]\n",
            " [0.95074129]\n",
            " [0.30092823]\n",
            " [0.86775841]]\n",
            "[[0.01139479]\n",
            " [0.95061214]\n",
            " [0.30089242]\n",
            " [0.86763798]]\n",
            "[[0.01119374]\n",
            " [0.95048313]\n",
            " [0.30085668]\n",
            " [0.8675178 ]]\n",
            "[[0.01099303]\n",
            " [0.95035426]\n",
            " [0.30082098]\n",
            " [0.86739787]]\n",
            "[[0.01079265]\n",
            " [0.95022552]\n",
            " [0.30078535]\n",
            " [0.86727818]]\n",
            "[[0.01059262]\n",
            " [0.95009691]\n",
            " [0.30074977]\n",
            " [0.86715874]]\n",
            "[[0.01039293]\n",
            " [0.94996844]\n",
            " [0.30071425]\n",
            " [0.86703955]]\n",
            "[[0.01019357]\n",
            " [0.9498401 ]\n",
            " [0.30067878]\n",
            " [0.8669206 ]]\n",
            "[[0.00999455]\n",
            " [0.9497119 ]\n",
            " [0.30064336]\n",
            " [0.86680189]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8Og96C_VAMD",
        "colab_type": "text"
      },
      "source": [
        "## Practice: Implementing a Linear Regression Model\n",
        "Steps to most ML projects:\n",
        "1. Pull in data\n",
        "2. Initialize weights\n",
        "3. Run gradient descent iteratively\n",
        "4. Test on new data\n",
        "5. Report results\n",
        "\n",
        "[Dataset!](https://archive.ics.uci.edu/ml/datasets/Auto+MPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YURiRRAxVtAW",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Pull in Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaqKTuisVnK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIMQFgI6bY5k",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Initialize Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FshluaffbZP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCtLWB12bc99",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Run Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxAlYaPobrG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1XhYfSibrXV",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Test on New Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SpySiFhbuWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q2hVkOSbwYy",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Report Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb4DikHIbyfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}